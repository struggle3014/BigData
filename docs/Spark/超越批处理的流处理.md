<div align="center"><img src="https://gitee.com/struggle3014/picBed/raw/master/name_code.png"></div>

# 导读

本文参考了 Google Beam 的 `Typler Akidua` 的系列文章 《The world beyond batch》。随着大数据计算框架的发展，流式计算的重要性在不断地提高。但是目前流式计算框架纷繁众多，我们只有抓住流式计算的基本原理，才能够轻松的掌握各种流式计算框架。

大数据领域，**流式计算越发重要**，主要有以下几点**原因：**

* 人们越来越想要获取更及时的数据，切换到流式数据处理是降低延迟的好办法。
* 海量数据的生产变得越来越繁，即使是小公司也会产生超大量的数据。因此必然需要一种系统能够处理这种无穷多的数据集合。
* 数据更快地被处理可以实现负载均衡，对资源的消耗也更加可控。

本文主要从以下几个方面作介绍：

* **常用术语（Terminology）**；如此复杂的讨论不明晰术语一定是举步维艰的。当前在流式处理的概念中名词歧义现象十分常见，故消除歧义明确含义的事情一定要首先完成。
* **数据处理模式**；分别对有界数据和无界数据常见的处理模式做了简单的介绍。
* **确定能力边界（Capabilities）**；知其为，也要知其不可为。流式处理系统能做什么，不能做什么，这是个大问题。
* 对于流处理引擎击败批处理引擎的**正确性**问题做了详细介绍。
* 对于流处理引擎击败批处理引擎的第一个需要解决的问题即**时间推理工具**做了详细介绍。

***持续更新中~***



# 目录

<nav>
<a href='#导读' style='text-decoration:none;font-weight:bolder'>导读</a><br/>
<a href='#目录' style='text-decoration:none;font-weight:bolder'>目录</a><br/>
<a href='#正文' style='text-decoration:none;font-weight:bolder'>正文</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1 常用术语（Terminology）' style='text-decoration:none;${border-style}'>1 常用术语（Terminology）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1.1 流是什么（What is streaming）' style='text-decoration:none;${border-style}'>1.1 流是什么（What is streaming）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1.2 时域（Time domains）' style='text-decoration:none;${border-style}'>1.2 时域（Time domains）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1.3 窗口（Window）' style='text-decoration:none;${border-style}'>1.3 窗口（Window）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1.4 水位线（Watermark）' style='text-decoration:none;${border-style}'>1.4 水位线（Watermark）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1.5 触发器（Trigger）' style='text-decoration:none;${border-style}'>1.5 触发器（Trigger）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1.6 容忍延迟（垃圾回收）' style='text-decoration:none;${border-style}'>1.6 容忍延迟（垃圾回收）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#1.7 堆积（Accumulation）' style='text-decoration:none;${border-style}'>1.7 堆积（Accumulation）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#2 数据处理模式（Data processing patterns）' style='text-decoration:none;${border-style}'>2 数据处理模式（Data processing patterns）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#2.1 有界数据' style='text-decoration:none;${border-style}'>2.1 有界数据</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#2.2 无界数据—批处理' style='text-decoration:none;${border-style}'>2.2 无界数据—批处理</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#2.3 无界数据—流处理' style='text-decoration:none;${border-style}'>2.3 无界数据—流处理</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#3 确定能力边界（Capabilities）' style='text-decoration:none;${border-style}'>3 确定能力边界（Capabilities）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#4 正确性如何实现' style='text-decoration:none;${border-style}'>4 正确性如何实现</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#4.1 有状态的流式处理' style='text-decoration:none;${border-style}'>4.1 有状态的流式处理</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#4.2 状态管理' style='text-decoration:none;${border-style}'>4.2 状态管理</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;<a href='#5 时间推理工具' style='text-decoration:none;${border-style}'>5 时间推理工具</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#5.1 <font color="blue">What</font> results are calculated？（计算了什么结果）' style='text-decoration:none;${border-style}'>5.1 <font color="blue">What</font> results are calculated？（计算了什么结果）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#5.2 <font color="green">Where</font> is event time are results calculated？（event time 在哪里计算结果）' style='text-decoration:none;${border-style}'>5.2 <font color="green">Where</font> is event time are results calculated？（event time 在哪里计算结果）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#5.3 <font color="pink">When</font> in processing time are results materialized？（在 processing time 中何时将结果物化）' style='text-decoration:none;${border-style}'>5.3 <font color="pink">When</font> in processing time are results materialized？（在 processing time 中何时将结果物化）</a><br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href='#5.4 <font color="orange">How</font> do refinements of results relate？（结果的细化是如何关联的）' style='text-decoration:none;${border-style}'>5.4 <font color="orange">How</font> do refinements of results relate？（结果的细化是如何关联的）</a><br/>
<a href='#总结' style='text-decoration:none;font-weight:bolder'>总结</a><br/>
<a href='#参考文献' style='text-decoration:none;font-weight:bolder'>参考文献</a><br/>
</nav>

# 正文

## 1 常用术语（Terminology）

### 1.1 流是什么（What is streaming）

术语上的不精确性使流的真正含义变得模糊，并且在某些情况下，流系统本身的负担意味着它们的能力局限于经常被描述为“流”的特性，例如近似或推测的结果。我们倾向于将术语与一个非常具体的含义隔离开：**一种设计时考虑到无限数据集的数据处理引擎**。该定义同时包括了真正的**流处理**和**微批处理**实现。

关于 "streaming" 的其他用法，以下是经常可以听到的一些用法，每种用法都有精确、描述性的术语：

1. **无限数据（unbounded data）**：**表示一直增长，无穷无尽的数据集合**，它们甚至被成为“流式数据（streaming data）”。这里的问题就在于当我们说 streaming 或 batch 时我们其实不是在表征它们处理的数据或特性。如前面所述，streaming 或 batch 的本质是处理这些数据的引擎，而非数据本身。streaming 和 batch 的主要区别在于其实也在于它们处理数据的有限性，所以刻画事物时应该抓住事物的本质。这类的数据的正确提法是：unbound data 和 unbound data，而不是流式数据。
2. **无限数据处理（unbound data processing）**：**应用在 unbounded data 上持续的数据处理**。把 streaming 解释成这个意思是有问题的，因为 batch 引擎其实也可以处理 unbounded data—重复多次地运行 batch 引擎已经被用于处理这类数据，所以要区分 streaming 和 unbounded data processing 的区别。
3. **低延迟，近似，或推测的结果**：这些类型的结果通常与流引擎相关。批处理系统传统上并没有在设计时考虑到低延迟或推测性的结果，这是历史的产物。当然，批处理引擎是完全能够产生近似的结果。因此，与上面的术语一样，将这些结果描述为它们是什么（低延迟，近似的，或推测的）要比描述它们在历史上是如何表现的（通过流引擎）要好的多。

**强调，streaming 表示的是用于处理 unbounded data 的执行引擎，仅此而已！**



### 1.2 时域（Time domains）

#### 1.2.1 时间域

要真正地谈论无界数据处理需要对所涉及的时间域有一个清晰的理解。在任何数据处理系统中，我们通常关心两个时间域:

无界数据处理先要搞时域的概念，在任何数据处理系统中，通常有两类时间维度的概念：

* **Event time**，即事件时间，事件真实发生的事件。

  基于 event time 使用场景：

  * 统计用户行为
  * 计费系统
  * 异常检测 

* **Processing time**，即处理事件，事件在系统中被观察到的事件。

  基于 processing time 使用场景：

  * 统计系统并发性处理能力



#### 1.2.2 造成 event time 和 processing time 不等的因素

理想状态下，event time 和 processing time 应该是相等的，即事件一旦发生就立即被处理。而实际上processing time 一般要晚于 event time，我们把两者的差值成为**时间倾斜**，或简称**倾斜（skew）**。**造成 skew 的因素**可能有输入源、执行引擎或硬件等。具体包括：

* **共享资源限制**：比如网络拥塞，网络分区，非专用环境中共享 CPU。

* **软件因素**：分布式系统逻辑，资源竞争。

* **数据本身的特性**：key 的分布，吞吐的差异，无序的变动。

以 event time 和 process time 为轴画一张图，那么真实场景下的数据倾斜分布类似于下面这样：

![streaming-skew](https://gitee.com/struggle3014/picBed/raw/master/streaming-skew.png)



### 1.3 窗口（Window）

#### 1.3.1 窗口的概念

时间窗口的本质**沿着时间维度把数据划分到不同的时间窗口中**。

#### 1.3.2 窗口的分类

![window-pattern](https://gitee.com/struggle3014/picBed/raw/master/window-pattern.png)

时间窗口大致可以分为以下三类：

* 固定窗口

  固定窗口把时间划分成固定大小的段。具体还可以细分为对齐窗口和未对齐窗口。

* 滑动窗口

  固定窗口的一种广义形式，滑动窗口也是固定的长度以及固定的间隔。如果间隔长度<窗口长度，那么窗口必然会造成重叠。如果间隔长度=窗口长度，那么就是固定窗口。如果间隔长度>窗口长度，被称为取样窗口，它只会查询一部分数据。滑动窗口一般是对齐的。

* 会话窗口

  属于动态窗口，会话是一组时间序列，通常被用于分析用户行为。既然是用户操作事件序列，我们无法提前为 session 定义窗口长度，而且由于实际中不同用户的 session 也是不同的，因此它们属于经典的未对齐窗口。



### 1.4 水位线（Watermark）

Watermark 是 event time 的**输入完整性**的临时标志。换个角度，它是系统衡量**事件流中消息被处理的进度与完整性**的指标。

![event-time-vs-processing-time](https://gitee.com/struggle3014/picBed/raw/master/event-time-vs-processing-time.png)

​														<font size=2>*event time 进度，时间倾斜（skew）和水位线（watermarks）*</font>

那条曲折的红线在现实中本质上就是 watermark；它体现了随 processing time 增长，event time 完整性的增长。概念上，你可以把 watermark 理解为一个函数，`F(P)->E`，拥有一个处理时间的参数，返回一个事件时间的结果。（更确切地讲，这个函数的输入其实是 watermark 观察到时整个流水线中所有上游的当前状态：输入源，缓冲区的数据，正在被处理的数据等；但是概念上，我们可以把它简单地理解为处理时间到事件时间的映射。）那个事件时间的时点，`E`，就是系统认为所有在事件时间之前发生的事件都已经可见的时点。换句话说，这是个假设：再也不会有在`E`之前的数据被系统观察到。基于Watermark的类型，完美或启发式，这个假设分别可能是硬性保证或是有根据的猜测。

**watermark 类型：**

* 完美式 watermark
  * 需要确切地认识到数据源，才构建完美 watermark。
  * 不会有迟到的数据，所有的数据都是提前或准时到达。
  * 缺点是太慢：当 watermark 因为处理队列中其他待处理的数据（比如日志输入被网络带宽限制）被阻塞的时候，那么如果仅仅依靠 watermark 去判断进度的话，输出就会滞后。
* 启发式 watermark
  * 事实上无法确切地认识到数据源。
  * 利用全部可用的关于输入源的信息（partitions，partitions中信息的顺序性，文件的增长率等）去尽可能推断一个大概的进展。
  * 会存在小部分数据是延迟到达的。
  * 缺点是太快：会损失部分数据。



### 1.5 触发器（Trigger）

为了解决 watermark 的“太快和太慢”的缺陷，需要引入 trigger 来解决。Trigger 描述了窗口合适应该发送输出。

**触发 trigger 信号：**

* 水位线进度（也就是 event time 进度）：event time 窗口完整了（watermark 到达窗口尾部，窗口的输出被发送；时间窗口过期，触发垃圾回收）。
* Processing time 进度：在按一定的时间间隔更新数据时非常有用，因为 processing time （不像 event time）总是稳定，无延迟的。
* 元素数量，在接收到一定数量的元素就触发的场景非常有用。
* 特定符号标志：该场景下，trigger 的触发依赖一个特定的符号数据（比如一次 flush 中的 EOF 标志）。

**触发器类别：**

* Repetitions（重复）：在配合按处理时间按一定时间间隔更新时有奇效。
* Conjunctions（逻辑AND）：当所有子 triggers 被触发时才触发（例如在收到 watermark 并且收到一个特定的符号标志的情况下才触发）。
* Disjunctions（逻辑OR）：当任意子 triggers 被触发时就触发（例如在收到 watermark 或者收到一个特定的符号标志的情况下就触发）。
* Sequences（顺序）：当子 triggers 按特定顺序被触发时才触发。

**触发器如何解决“完美式 watermark 太快和启发式 watermark 太慢”缺陷：**

在太快和太慢两个场景中，我们本质上希望使得一个窗口的输出比较规律，或早于或晚于 watermark 经过窗口尾部时间，所以需要某种重复的 trigger。

* **太慢**

  在太慢的场景中（也就是获得一个早期推测的结果），我们可以假设：还有很多该窗口的数据尚未到达。这样，随着 processing time 的推移重复地触发窗口是明智的，因为触发条件并不依赖于窗口内的数据量；最坏的情况就是得到一个周期性触发的稳定的流。

* **太快**

  在太快的场景中（也就是依据迟到数据修正因为启发式 watermark 早到而产生的错误结果），我们假设启发式 watermark 是相对准确的（一个合理的安全假设）。该场景中，不会有过多迟到的数据。但是我们一旦收到一条迟到的数据，期望尽快修正之前的结果（收到迟到的数据即刻触发）。

我们需要根据不同的场景（或根本不选择）合适的 trigger。



### 1.6 容忍延迟（垃圾回收）

triggers 的一个非常有趣的作用是使得完美式 watermark 与启发式 watermark 的输出模式趋同。现在他们最大的不同就是窗口的生命周期。在完美式 watermark ，我们知道一旦 watermark 到达，不会再有迟到的数据，所以我们可以直接清空窗口的所有状态。但在启发式 watermark 的场景中，当 watermark 到达窗口后还会等待一段时间内到达的迟到数据。但是实际上，我们系统并不知道迟到的数据会迟到多久，也就不知道窗口要等待多久。所以提出了“容忍延迟（Allowed Lateness）”的概念。

容忍延迟是在 event time 定义一个系统是否处理迟到数据的时点边界。定义了该时点边界，我们能够大致估算出窗口的状态需要保存多久：当 watermark 大于边界时点时，该时点之后到达的数据均丢弃。



### 1.7 堆积（Accumulation）

当 trigger 能够使得一个窗口产生多次窗格数据时，我们需要解决这样的问题，即“**结果的细化是如何关联的**”。

**堆积的模式：**

* Discarding（丢弃）：当一个窗格发出后，丢弃所有的状态。这意味着所有相邻的窗格都是独立的。丢弃模式在下游自行聚积的场景下十分有用，比如下游系统希望每次接收增量改变，而非全量结果。
* Accumulating（聚积）：如图7所示，窗格每次发出结果，状态均被保留，稍晚的输入将被聚积到之前的状态中。这意味着任意相邻的窗格都依赖于前一个窗格。聚积模式在下游直接覆盖之前结果的场景下非常有用，就如使用 BigTable 或 HBase 直接存储键值对那样。
* Accumulating & retracting（聚积&撤销）：类似聚积模式，但是当产生一个新窗格的同时，产生对于之前窗格的一些回撤。回撤（结合新产生的聚积值）本质上是在明确地表达：“我之前跟你说结果是X，但特么我错了。别管上次的X了，把X用Y替换掉。”在两种场景下回撤相当有用：
  * 当消费下游会根据不同的维度重组数据，有可能新数据与旧数据维度不同，应该被归为另一组。这样，新数据就不能直接替换老数据；相反，你需要从老数据那组回撤老数据，并在新数据那组增加新数据。
  * 当使用动态窗口（也就是会话窗口）的时候，因为窗口合并，新数据可能不仅仅是替换老数据。这种场景下，新窗口自身很难决定哪些老窗口会被合并，相反的撤销所有的老窗口相对简单暴力。



## 2 数据处理模式（Data processing patterns）

接下来，我们研究下有界和无界数据处理的常见模式的核心类型。

### 2.1 有界数据

![bounded data processing](https://gitee.com/struggle3014/picBed/raw/master/bounded-data-processing.png)

​																<font size=2>*使用经典的批处理引擎处理有界数据*</font>

上图左侧的数据杂乱无章，运行某个数据处理引擎后（通常是 batch 引擎，如 MapReduce）变成了右边更有序的数据。

### 2.2 无界数据—批处理

批处理引擎虽然在设计时没有考虑到无界数据，但自从第一次构思批处理系统以来，就一直用于处理无界数据集。这些方法的**核心是将无界数据分割成适合批处理的有界数据集集合**。

#### 2.2.1 固定窗口

![unbounded-data-processing](https://gitee.com/struggle3014/picBed/raw/master/unbounded-data-processing.png)

​													<font size=2>*使用经典的批处理引擎通过特定的固定窗口进行无限制的数据处理*</font>

使用批处理引擎的重复运行来处理无界数据集的最常见方法是将输入数据窗口化为固定大小的窗口，然后将每个窗口作为单独的有界数据源进行处理。特别是对输入源像日志,事件可以写入目录和文件层次结构的名字编码对应的窗口,这样的事情似乎很简单的乍一看既然你已经基本上完成了基于时间的 shuffle 数据到相应的事件提前时间窗口。

然而，在现实中，大多数系统仍然有一个完整性问题需要处理:如果您的一些事件由于网络分区而在通往日志的路上被延迟了怎么办?如果您的事件是全局收集的，并且必须在处理之前转移到一个公共位置，那该怎么办?如果你的事件来自移动设备呢?这意味着某种程度的缓解可能是必要的(例如，延迟处理，直到您确定所有事件都已收集完毕，或者每当数据延迟到达时，对给定窗口的整个批处理进行重新处理)。

#### 2.2.2 会话窗口

![unbounded-data-processing-session](https://gitee.com/struggle3014/picBed/raw/master/unbounded-data-processing-session.png)

​												<font size=2>*使用经典的批处理引擎，通过特定的固定窗口将未绑定的数据处理到会话中*</font>

当您尝试使用批处理引擎将未绑定的数据处理为更复杂的窗口策略(如会话)时，这种方法会更加失效。会话通常被定义为活动期间(例如，对于特定的用户)，在活动间隙结束。当使用典型的批处理引擎计算会话时，您通常会得到**在多个批之间分割的会话**，如下图中的红色标记所示。

* 可以通过增加批大小来减少分割的数量，但代价是增加了延迟。
* 添加额外的逻辑来连接以前运行的会话，但代价是进一步增加复杂性。

不管怎样，使用传统的批处理引擎来计算会话都是不理想的。一种更好的方法是以流方式构建会话。

### 2.3 无界数据—流处理

与大多数基于批处理的无界数据处理方法的即席特性相反，流系统是为无界数据构建的。如前所述，对于许多实际的分布式输入源，您不仅要处理无界数据，还要处理以下数据:

* **高度无序的 event time**：这意味着，如果希望在数据发生的上下文中分析数据，则需要在管道中进行某种基于时间的转移。
* **不同的 event time 偏差（skew）**：这意味着你不能假设你总是能看到给定事件X的大部分数据在某个常数Y范围内。

处理具有上述特征的数据时，可以采用下面几类方法：

* 与时间无关（Time-agnostic）
* 近似算法
* 基于 processing time 的窗口
* 基于 event time 的窗口



#### 2.2.1 与时间无关（Time-agnostic）

本质上不关心时间（如所有逻辑都是数据驱动的）。现有的流系统天然支持这种与时间无关的使用场景。批处理系统也非常适合这种时间无关性的数据处理，将无界数据源分割成任意的有界数据集序列，然后独立地处理这些数据集。

**过滤（filtering）**

![filtering-unbounded-data](https://gitee.com/struggle3014/picBed/raw/master/filtering-unbounded-data.png)

​																					<font size=2>*过滤无界数据*</font>

 假设我们处理的是Web流量日志，想要过滤出某个特定领域来的所有流量，那么我们只需查看每条日志的来源，如果不符合条件直接pass掉。显然这和时间是没有关系的，因此数据源是否是无序，无界或是变动的时间倾斜（skew）就显得不重要了。

**内连接（Inner-joins）**

![inner-join-on-unbounded-data](https://gitee.com/struggle3014/picBed/raw/master/inner-join-on-unbounded-data.png)

​																				<font size=2>*在无界数据上执行内连接*</font>

当连接两个无穷数据源时倘若我们只在乎连接的结果，则处理逻辑就不需要考虑时间的因素。一旦看到某股输入源中出现一个值，那么我们就把这个值缓存起来。当值出现在第二股输入源时，只需要发送合并的消息即可。

*<font color=red>思考：如果是外连接呢？</font>*

引入数据完备性的问题：一旦看到了 join 的一边，那么如何才能确定另一边也到达了呢？实际上是没法得知的，此时必须引入某种超时机制—而这必然会引入时间因素。时间因素本质上就是时间窗口的形式。

#### 2.2.2 近似算法

![compute-approximations-on-unbounded-data](https://gitee.com/struggle3014/picBed/raw/master/compute-approximations-on-unbounded-data.png)

​																				<font size=2>*在无界数据上计算近似值*</font>

近似算法，比如近似的TopN，streaming K-means等。这些算法接收无穷数据源作为输入，而输出结果只能算是基本上满足我们的预期。近似算法的好处在于开销很低并且天生就是用于处理无穷数据集的，而缺点在于算法通常是很复杂的，而且它们的近似特性限制了它们的应用。

#### 2.2.3 基于 processing time 的窗口

![windowing-fixed-windows-processing-time](https://gitee.com/struggle3014/picBed/raw/master/windowing-fixed-windows-processing-time.png)

​																			<font size=2>*通过 processing time窗口进入固定窗口*</font>

根据 processing time 创建时间窗口时，系统会缓存输入数据到窗口中直至超过了某段时间。比方说对于5分钟的固定时间窗口，系统会缓存之前5分钟的所有数据并封装进一个窗口中，之后发送给下游系统用于处理。

窗口特点：

* 简单
* 极易检验完备性：系统完全知道所有输入数据都已经到来，无需处理延迟数据。
* 适用于数据被观察产生价值的使用场景：如通过计算每秒请求的变化来判断是否出现服务中断。

窗口缺点：

 * 必须要求数据按 event time 顺序到达，否则无法真实再现事件发生场景。
   * App 收集用户统计信息。当手机未连网络，某段时间的数据就无法上传。在 processing time 窗口，无法有用数据。
   * 收集全球金融市场的行情数据。当网络问题导致带宽受阻，会造成数据的 skew。

#### 2.2.4 基于 event time 的窗口

为了修复 processing time 的窗口的缺陷，我们需要基于 event time 的窗口。

​							![windowing-fixed-windows-event-time](https://gitee.com/struggle3014/picBed/raw/master/windowing-fixed-windows-event-time.png)																		<font size=2>*基于 event time 窗口进入固定窗口*</font>																

两条白线表明了两个特殊的数据：这两个数据点上的数据对应的processing time时间窗口与基于event time的时间窗口是错配的。因此如果使用基于processing time的时间窗口必然造成结果的不准确。由此可见，能够提供正确性是基于event time时间窗口的一大优势。



![windowing-session-windows-event-time](https://gitee.com/struggle3014/picBed/raw/master/windowing-session-windows-event-time.png)

​																		<font size=2>基于 event time 窗口进入会话窗口</font>

基于event time时间窗口的另一个优势在于它的大小可以动态变更，比如session，再不会有跨batch或跨窗口的情形发生。

窗口缺陷：

* 需要额外缓存：因为时间窗口的时间周期拉长了，需要缓存更多的数据。
* 完备性：因为无法明确得知某个窗口下所有的数据都已经到来，因此便无法确认何时才能处理该窗口。在实践中，系统需要给定一个经验值来定义窗口的完备性。但从绝对正确的角度来考虑，唯一解决方法就是提供一种方式能够让数据可以被重新处理从而不断修正计算结果。



## 3 确定能力边界（Capabilities）

我们讨论下流系统（streaming system）能做什么和不能做什么，重点是能做什么。流系统长期以来被纳入一个提供低延迟、不准确/猜测性结果的小众市场，通常与更有能力的批处理系统一起提供最终正确的结果，即 Lambda 架构。

Lambda 架构（Apache Storm 作者 Nathan Marz 提出）的基本思想是运行一个流系统和一个批处理系统，两者执行的结果基本相同。流系统提供低延迟、不准确结果（可能是使用了近似算法，或者流系统本身没有提供正确性），一段时间之后，批处理系统会继续运行，并提供正确输出。不过 Lambda 架构有个缺点：需要构建、提供和维护管道的两个独立版本，然后最后以某种方式合并两个管道的结果。

Typler 对于强一致流引擎有着很深的造诣，不赞同 Lambda 架构设计，但却是 Jay Kreps （Kafka 作者）提出可重演系统的拥趸：使用 Kafka 这样的可重演系统连接流引擎作为流互连的上下文中解决可重复性的问题，甚至提出了 Kappa 架构，并自始自终使用一套管道来管理数据。更进一步，我们可以认为定义良好的流系统甚至提供的是批处理引擎所具有功能的超集（superset）。事实上，Flink 就是基于该思想，构建了一个随时随地流化的系统，即使是批模式，Flink 底层也是使用 streaming 实现的。

流系统的广泛成熟与无限数据处理的健壮框架相结合，最终使得 Lambda 架构逐步退出历史舞台。不过流系统要打败批处理系统，还需要完成两件事：

1. **正确性**—与批处理平起平坐。

   从本质上说，正确性可以归为一致性存储。流系统需要有能力定期地持久化状态（checkpoint），并且需要能够维护系统崩溃下的一致性。当下，很多流系统能够做到最多一次的处理（at-most-once processing），最多一次处理语义是伪命题，但目前它仍然存在。**再次强调：强一致（strong consistency）是实现精确一次处理（exactly-once processing）语义的必要条件，精确一次处理（exactly-once processing）语义是实现正确性的必要条件，而任何流系统想要打败批处理系统必须要实现正确性。**流系统获取强一致，参考 MilWheel 和 Spark Streaming 论文。

2. **时间推理工具**—超越批处理。

   时间推理工具能够处理无界，无序数据。



## 4 正确性如何实现

在介绍正确性之前，先介绍**有状态的流式处理**的基本概念：

### 4.1 有状态的流式处理

#### 4.1.1 流式处理

![plain-streaming-process](https://gitee.com/struggle3014/picBed/raw/master/plain-streaming-process.png)

流式处理简单来讲即有一个无穷无尽的数据源在持续收取数据，以代码作为数据处理的基础逻辑，数据源的数据经过代码处理后产生出结果，然后输出，这就是流式处理的基本原理。



#### 4.1.2 分布式流式处理

![distributed-streaming-process](https://gitee.com/struggle3014/picBed/raw/master/distributed-streaming-process.png)

假设 Input Streams 有很多个使用者，每个使用者都有自己的 ID，如果计算每个使用者出现的次数，我们需要让同一个使用者的出现事件流到同一运算代码，这跟其他批次需要做 group by 是同样的概念，所以跟 Stream 一样需要做分区，设定相应的 key，然后让同样的 key 流到同一个 computation instance 做同样的运算。



#### 4.1.3 有状态分布式流式处理

* 基于内存的状态存储

  ![state-distributed-streaming-process-memory](https://gitee.com/struggle3014/picBed/raw/master/state-distributed-streaming-process-memory.png)

  

  如图，上述代码中定义了变数 X，X 在数据处理过程中会进行读和写，在最后输出结果时，可以依据变数 X 决定输出的内容，即状态 X 会影响最终的输出结果。这个过程中，第一个重点是先进行了状态 co-partitioned key by，同样的 key 都会流到 computation instance，与使用者出现次数的原理相同，次数即所谓的状态，这个状态一定会跟同一个 key 的事件累积在同一个 computation instance。

* 基于嵌入式数据库的状态存储

  ![state-distributed-streaming-process-embedded](https://gitee.com/struggle3014/picBed/raw/master/state-distributed-streaming-process-embedded.png)
  相当于根据输入流的 key 重新分区的 状态，当分区进入 stream 之后，这个 stream 会累积起来的状态也变成 copartiton 了。第二个重点是 embeded local state backend。有状态分散式流式处理的引擎，状态可能会累积到非常大，当 key 非常多时，状态可能就会超出单一节点的 memory 的负荷量，这时候状态必须有状态后端去维护它；在这个状态后端在正常状况下，用 in-memory 维护即可。



### 4.2 状态管理

正确性可以归为一致性存储。而一致性存储的核心即对于各类状态的管理，包括状态容错，状态维护，状态转移。

#### 4.2.1 状态容错

状态容错主要包含以下几点：

* 如何确保状态具有精确一次（exactly-once）的容错保证？

* 如何在分布式场景下替换多个拥有本地状态的运算子产生一个全域一致的快照（global consistent snapshot）？

* 如何在不中断算子的前提下产生快照？



##### 4.2.1.1 简单场景的精准一次容错方法

最简单的使用场景，如无限流的数据进入，后面单一的 Process 进行运算，每处理完一笔计算即会累积一次状态，这种情况下如果要确保 Process 产生精确一次的状态容错，每处理完一笔数据，更改完状态后进行一次快照，快照包含在队列中并与相应的状态进行对比，完成一致的快照，就能确保精确一次。



##### 4.2.1.2 分布式容错状态

* **生成全域一致快照**。在分布式的场景下，进行多个本地状态的运算，只产生一个全域一致的快照（global consistent snapshot）。![global-consistent-snapshot](https://gitee.com/struggle3014/picBed/raw/master/global-consistent-snapshot.png)

当 operator 在分布式的环境中，在各个节点做运算，首先产生 global consistent snapshot 的方式就是处理每一笔数据的快照点是连续的，这笔运算流过所有的运算值，更改完所有的运算值后，能够看到每一个运算值的状态（state）与该笔运算的位置（offset），即可称为 consistent snapshot。

checkpoint，上面提到连续性快照每个 operator 运算值本地的状态后端都要维护状态，也就是每次将产生检查点（checkpoint）时会将它们传入共享的 DFS 中。

* **容错恢复**

  ![distributed-state-restore](https://gitee.com/struggle3014/picBed/raw/master/distributed-state-restore.png)

  当任何一个 process 挂掉后，可以直接从三个完整的 checkpoint 将所有的运算值的状态恢复，重新设定到相应位置。checkpoint 的存在使整个 process 能够实现分散式环境中的 exactly-once。

##### 4.2.1.3 分散式快照（distributed snapshots）方法

如何在不中断运算的情况下持续产生 global consistent snapshot，其方式是基于用 simple lamport 演算法机制下延伸的。在 dataStream 中不断地安插 checkpoint barrier。checkpoint barrier N 代表着所有在这个范围里面的数据都是 Checkpoint barrier N。

![distributed-snapshot-data-stream](https://gitee.com/struggle3014/picBed/raw/master/distributed-snapshot-data-stream.png)

![distributed-snapshot-step1](https://gitee.com/struggle3014/picBed/raw/master/distributed-snapshot-step1.png)

例如：需要产生 checkpoint barrier N，checkpoint 被触发后开始从数据源产生 checkpoint barrier。当 job 开始做 checkpoint barrier N 的时候，可以理解为 checkpoint barrier N 需要逐步填充左下角的表格。

当部分事件标为红色，checkpoint barrier N 也是红色时，代表着这些数据或事件都由 checkpoint barrier N 负责。其他颜色的数据或事件不属于 checkpoint barrier N。

当数据源收到 checkpoint barrier N 之后会先将自己的状态保存，以读取 Kafka 资料为例，数据源的状态就是目前它在 Kafka 分区的位置，这个状态也会写入到表格中。

![distributed-snapshot-step2](https://gitee.com/struggle3014/picBed/raw/master/distributed-snapshot-step2.png)

下游的 operator 1 会开始运算属于 checkpoint barrier N 的数据，当 checkpoint barrier N 跟着这些数据流动到 operator 1 之后,operator 1 也将属于 checkpoint barrier N 的所有数据都反映在状态中，当收到 checkpoint barrier N 时也会直接对 checkpoint 去做快照。

![distributed-snapshot-step3](https://gitee.com/struggle3014/picBed/raw/master/distributed-snapshot-step3.png)

当快照完成后继续往下游走，operator 2 也会接收到所有数据，然后搜索 checkpoint barrier N 的数据并直接反映到状态，当状态收到 checkpoint barrier N 之后也会直接写入到 checkpoint N 中。以上过程到此可以看到 checkpoint barrier N 已经完成了一个完整的表格，这个表格叫做 **distributed snapshots**，即**分布式快照**。分布式快照可以用来做状态容错，任何一个节点挂掉的时候可以在之前的 Checkpoint 中将其恢复。

继续以上过程，当多个 checkpoint 同时进行，checkpoint barrier N 已经流到 job manager 2，Flink job manager 可以触发其他的 checkpoint。

#### 4.2.2 状态维护

状态维护即用一段代码在本地维护状态值，当状态值非常大时需要本地的状态后端来支持。

* Java Heap 状态后端，适用于数据量较小的

![state-maintenance-java-heap](https://gitee.com/struggle3014/picBed/raw/master/state-maintenance-java-heap.png)

* 内嵌数据库状态后端，适合数据量较大的。

![state-maintenance-embedded](https://gitee.com/struggle3014/picBed/raw/master/state-maintenance-embedded.png)

#### 4.2.3 状态转移

在流式处理应用无时无刻不在运行，运维时需要考虑以下几个问题：

* 更改逻辑/修复 bug 时，如何将前一个执行状态迁移到新的执行？

* 如何重新定义运行的平行化程度？

* 如何升级集群的版本号？

解决方案为：保存点（savepoint），当手动触发一个 checkpoint 时，就叫做 savepoint。

savepoint 和  checkpoint 的差别在于：checkpoint 是流式计算引擎对于一个有状态应用在运行中利用分布式快照持续周期性产生的，而 savepoint 是手动产生的 checkpoint。



## 5 时间推理工具

时间推理需要解决以下几个问题：

### 5.1 <font color="blue">What</font> results are calculated？（计算了什么结果）

流水线中各种转换函数。包括计算求和，构建直方图，训练机器、学习模型等。



每一个动画描绘了两个维度上的输入与输出：事件时间（X轴）和处理时间（Y轴），这样，流水线进展中观测到的真实时间的流逝就是从底部到顶部，就像上升的粗白线标注的那样。输入是一个个圈，圈中的数字代表每个输入具体的数值。它们开始是灰色的并将会在流水线观测到它们时改变颜色。

<iframe height=498 width=510 src="https://embedwistia-a.akamaihd.net/deliveries/3116f7c9159e25b3bd5ff05fa6a3adf1f53c6252/file.mp4">

​																		<font size=2>**Classic batch processing**</font>

### 5.2 <font color="green">Where</font> is event time are results calculated？（event time 在哪里计算结果）

* 处理流水线中 event time 窗口的使用，包括常见的窗口（固定窗口、滑动窗口和会话窗口）。
* 无窗口使用场景，一些与时间无关的场景，传统的批处理场景。
* 复杂窗口类型，例如限时拍卖。

<iframe height=498 width=510 src="https://embedwistia-a.akamaihd.net/deliveries/29b524c8d427de5db2b7e80d4e0964bcfa546ab8/file.mp4">

​																<font size=2>**Windowed summation on a batch engine**</font>



<iframe height=498 width=510 src="https://embedwistia-a.akamaihd.net/deliveries/a956f3a2e3da28718444e303672bfebf450b3437/file.mp4">

​							<font size=2>**Windowed summation on a streaming engine with early and late firings**</font>



### 5.3 <font color="pink">When</font> in processing time are results materialized？（在 processing time 中何时将结果物化）

结合 watermarks 与 triggers 的使用。这个主题可以有无数种变形，但是最常见的使用模式是利用 watermarks 划分特定窗口的边界，同时使用 triggers 允许在窗口数据完整之前（为了实时估算，部分数据在窗口内数据完整前便发送结果）或之后（在 watermark 仅仅作为窗口完整的大致参考的场景下，更多数据输入可能在 watermark 之后到达）。

<iframe height=498 width=510 src="https://embedwistia-a.akamaihd.net/deliveries/0fe570080208aa6b0b2a44790a95813e08889fdc/file.mp4">

​					<font size=2>**Windowed summation on a streaming engine with early and late firings and allowed**</font>

### 5.4 <font color="orange">How</font> do refinements of results relate？（结果的细化是如何关联的）

选用了哪种 accumulation：discarding（多个结果都是独立且不同的），accumulating（后期结果依赖前期结果）和 retracting（accumulating 的值外加回撤之前触发的值一起发出）。

<iframe height=498 width=510 src="https://embedwistia-a.akamaihd.net/deliveries/4a74df3fe91c2aeb1e77a96218c08c6d25fd7632/file.mp4">

​										<font size=2>**Discarding mode version of early/late firings on a streaming engine**</font>



<iframe height=498 width=510 src="https://embed-fastly.wistia.com/deliveries/69dc164b3c205a742ee4fa663312dc5f74358cb5/file.mp4">

​							<font size=2>**Accumulating & retracting mode version of early/late firings on a streaming engine**</font>



# 总结

本文首先介绍了流式处理中常见的术语，接着对于数据的处理模式做了分类说明，再者，就是确定了流处理的能力边界，最后对于流处理击败批处理的两个能力做了详细说明，即正确性如何实现和时间推理工具。



# 参考文献

[1] [O'REILLY—Streaming 101：The world beyond batch](https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/)

[2] [O'REILLY—Streaming 102：The world beyond batch](https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/)

[3] [微信公众号— Flink 中文社区— Apache Flink 基础概念解析](https://mp.weixin.qq.com/s/oBmRhRA-52CLRLXp6sZwEw)

[4] [Spark 官网—Structured Streaming 编程指南](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)

[5] [Spark 官网—Spark Streaming 编程指南](http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)